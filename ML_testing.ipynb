{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yifan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Yifan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Yifan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#set up x and y\n",
    "from statistics import mean\n",
    "x = []\n",
    "y = []\n",
    "#shrink the data size of FR signals\n",
    "#FR signals updated every 2 seconds and we taked the average per minute.Therefore, we can get 60 data for each hour.\n",
    "\n",
    "NumOfData = 600# the number of data selected in one hour\n",
    "FR_signal = np.zeros((8760,NumOfData))\n",
    "\n",
    "signal = []\n",
    "\n",
    "for i in range (12):\n",
    "    if i < 9:\n",
    "        filename = 'FR/0'+str(i+1)+'_2017_Dynamic.csv'\n",
    "    else:\n",
    "        filename = 'FR/'+str(i+1)+'_2017_Dynamic.csv'\n",
    "    \n",
    "    data0 = pd.read_csv(filename,header=None) \n",
    "    signal0 = data0.as_matrix(columns=None)\n",
    "    signal0 = signal0.reshape(-1)\n",
    "    signal = np.append(signal,signal0)\n",
    "    \n",
    "for i in range (8760):\n",
    "    for j in range (NumOfData):\n",
    "        FR_signal[i,j] = mean(signal[i*1800+j*int(1800/NumOfData):i*1800+j*int(1800/NumOfData)+(int(1800/NumOfData)-1)])\n",
    "    \n",
    "#read the file of grid-price \n",
    "grid_price = np.zeros((8760,1))#construct a 8760*1 array\n",
    "\n",
    "data1 = pd.read_csv('FR/slow_Price.csv',header=None)\n",
    "#df = data1.shape\n",
    "#print(df)\n",
    "A = data1.as_matrix(columns=None) #convert the dataframe to an array\n",
    "grid_price0 = A.reshape(-1) #reduced the dimensions of the array to 1d\n",
    "\n",
    "for i in range (8760):\n",
    "    grid_price[i,0]=grid_price0[i] # transpose the array and then make sure FR_signal and grid price has the same dimension\n",
    "\n",
    "\n",
    "\n",
    "#read the file of FR price\n",
    "FR_price = np.zeros((8760,1))\n",
    "\n",
    "data2 = pd.read_csv('FR/FR_Incentive.csv',header=None)\n",
    "B = data2.as_matrix(columns=None)\n",
    "FR_price0 = B.reshape(-1)\n",
    "\n",
    "for i in range (8760):\n",
    "    FR_price[i,0] = FR_price0[i]\n",
    "    \n",
    "\n",
    "#read the file of soc\n",
    "soc = np.zeros((8760,1))\n",
    "data3 = pd.read_csv('soc_list.csv',header=None)\n",
    "\n",
    "for i in range (8760):\n",
    "    soc[i,0] = data3.iloc[i,0]\n",
    "\n",
    "\n",
    "#read the file of capacity remain\n",
    "capacity_remain = np.zeros((8760,1))\n",
    "data4 = pd.read_csv('capacity_remain_list.csv',header=None)\n",
    "\n",
    "for i in range (8760):\n",
    "    capacity_remain[i,0] = data4.iloc[i,0]\n",
    "\n",
    "#read the file of power purchased\n",
    "buy_from_grid = np.zeros((8760,1))\n",
    "data5=pd.read_csv('buy_from_grid.csv',header=None)\n",
    "\n",
    "for i in range (8760):\n",
    "    buy_from_grid[i,0] = data5.iloc[i,0]\n",
    "    \n",
    "\n",
    "#read the file of FR_Band\n",
    "FR_band = np.zeros((8760,1))\n",
    "data6 = pd.read_csv('FR_band_list.csv',header=None)\n",
    "\n",
    "for i in range (8760):\n",
    "    FR_band[i,0] = data6.iloc[i,0]\n",
    "\n",
    "#read the file of status list\n",
    "status = []\n",
    "data7 = pd.read_csv('status_list.csv',header=None)\n",
    "status = data7.iloc[:,0]\n",
    "\n",
    "#construct x and y\n",
    "xx = np.append(FR_signal, grid_price, axis=1)\n",
    "xx = np.append(xx, FR_price, axis=1)\n",
    "xx = np.append(xx, soc, axis=1)\n",
    "xx = np.append(xx, capacity_remain, axis=1)\n",
    "\n",
    "yy = np.append(buy_from_grid, FR_band, axis=1)\n",
    "\n",
    "retire_time_s = 24832800\n",
    "retire_time_hr = int(retire_time_s/3600)\n",
    "\n",
    "deleteIndex = []\n",
    "for i in range (retire_time_hr):\n",
    "    if status[i] == 0:\n",
    "        deleteIndex.append(i)\n",
    "x = xx[0:retire_time_hr,:]\n",
    "y = yy[0:retire_time_hr,:]\n",
    "\n",
    "\n",
    "#print(deleteIndex)\n",
    "x = np.delete(x, deleteIndex, axis=0)\n",
    "y = np.delete(y, deleteIndex, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nxLabels = ['']*64\\n\\nfor i in range (60):\\n    xLabels[i] = 'FR_signal'+str(i+1)\\nxLabels[60] = 'grid_price'\\nxLabels[61] = 'FR_price'\\nxLabels[62] = 'soc'\\nxLabels[63] = 'capacity_remain' \\n\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = x\n",
    "YY = y[:,1]\n",
    "n = XX.shape\n",
    "lenth = n[0]\n",
    "\n",
    "index =list(range(lenth))\n",
    "#print(index)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "# Scaling X\n",
    "sc = StandardScaler()\n",
    "XX = sc.fit_transform(XX)\n",
    "#Y = sc.fit_transform(Y)\n",
    "\n",
    "X=XX[index,:]\n",
    "Y=YY[index]\n",
    "#for i in range (lenth):\n",
    "#    X[i,:] = XX[index[i],:]\n",
    "#    Y[i] = YY[index[i]]\n",
    "    \n",
    "numData = 500\n",
    "numTrain = int(numData * 0.7)\n",
    "numTest = int(numData * .15)\n",
    "\n",
    "y_train, y_valid, y_test, y_train_valid = Y[:numTrain], Y[numTrain:-numTest], Y[-numTest:], Y[:-numTest]\n",
    "\n",
    "X_train, X_valid, X_test, X_train_valid = X[:numTrain, :], X[numTrain:-numTest, :], X[-numTest:, :], X[:-numTest, :]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "xLabels = ['']*64\n",
    "\n",
    "for i in range (60):\n",
    "    xLabels[i] = 'FR_signal'+str(i+1)\n",
    "xLabels[60] = 'grid_price'\n",
    "xLabels[61] = 'FR_price'\n",
    "xLabels[62] = 'soc'\n",
    "xLabels[63] = 'capacity_remain' \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Linear Regression ------------------\n",
      "training error 23.312348223015857\n",
      "Linear regression Mean Absolute Error: 21.497397968125387\n",
      "Linear regression Mean Squared Error: 796.1428892844029\n",
      "Linear regression Root Mean Squared Error: 28.216004133902498\n",
      "Ending Linear Regression ------------------\n"
     ]
    }
   ],
   "source": [
    "# Simple Linear Regression\n",
    "###\n",
    "print(\"Staring Linear Regression ------------------\")\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train_valid, y_train_valid)\n",
    "#coeffs = dict(zip(xLabels, regr.coef_))\n",
    "\n",
    "\n",
    "y_train_pred = regr.predict(X_train_valid)\n",
    "print(\"training error\", metrics.mean_absolute_error(y_train_pred, y_train_valid))\n",
    "\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "\n",
    "predAndActual = pd.DataFrame({'pred_y2':y_pred,'test_y2':y_test})\n",
    "#pd.DataFrame({'Pred_y1': y_pred, 'Test_y1': y_test})#'Pred_y2':y_pred[:,1],'Test_y2':y_test[:,1]})\n",
    "predAndActual.to_csv(\"OverallSimpleLinear.csv\")\n",
    "\n",
    "print('Linear regression Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Linear regression Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Linear regression Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print(\"Ending Linear Regression ------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_train=regr.predict(X_train_valid)\n",
    "#metrics.mean_absolute_error(y_pred_train, y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Ridge Regression ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yifan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:165: LinAlgWarning: Ill-conditioned matrix (rcond=3.45016e-19): result may not be accurate.\n",
      "  overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression best alpha is:  100\n",
      "Ridge Regression Mean Absolute Error: 18.793293535473623\n",
      "Ridge Regression Mean Squared Error: 577.9540233360201\n",
      "Ridge Regression Root Mean Squared Error: 24.040674352771806\n",
      "Ending Ridge Regression ------------------\n"
     ]
    }
   ],
   "source": [
    "##Ridge Regression\n",
    "print(\"Staring Ridge Regression ------------------\")\n",
    "\n",
    "# alphas = [0]\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 100]\n",
    "errors = []\n",
    "\n",
    "# Creating Different models for different alphas\n",
    "for a in alphas:\n",
    "    ridgeModel = Ridge(alpha=a)\n",
    "    ridgeModel.fit(X_train, y_train)\n",
    "    y_pred = ridgeModel.predict(X_valid)\n",
    "    error = metrics.mean_absolute_error(y_valid, y_pred)\n",
    "    errors.append(error)\n",
    "\n",
    "best_alpha = alphas[np.argmin(errors)]\n",
    "print(\"Ridge Regression best alpha is: \", best_alpha)\n",
    "\n",
    "best_model = Ridge(alpha=best_alpha)\n",
    "best_model.fit(X_train_valid, y_train_valid)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "predAndActual = pd.DataFrame({'pred_y2': y_pred,'test_y2': y_test})\n",
    "#pd.DataFrame({'Pred_y1': y_pred[:,0], 'Test_y1': y_test[:,0],'Pred_y2':y_pred[:,1],'Test_y2':y_test[:,1]})\n",
    "predAndActual.to_csv(\"OverallRidge.csv\")\n",
    "\n",
    "# Evaluation\n",
    "print('Ridge Regression Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Ridge Regression Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Ridge Regression Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "#print(\"Ridge Regression Coefficients: \", best_model.coef_)\n",
    "\n",
    "print(\"Ending Ridge Regression ------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Support Vector Regression ------------------\n",
      "SVR Best kernel for y2 is:  rbf\n",
      "SVR Best Epsilon for y2 is:  5\n",
      "SVR Best C for y2 is:  0.1\n",
      "SVR Best Gamma for y2 is:  auto\n",
      "SVR Mean Absolute Error for y2: 15.451197151848445\n",
      "SVR Mean Squared Error for y2: 462.5665903669757\n",
      "SVR Root Mean Squared Error for y2: 21.507361306468436\n",
      "Ending Support Vector Regression for y2------------------\n"
     ]
    }
   ],
   "source": [
    "# SVM Models\n",
    "\n",
    "print(\"Starting Support Vector Regression ------------------\")\n",
    "\n",
    "kernels = ['poly', 'rbf', 'linear']\n",
    "epsilons = [0.1, 5, 10, 20]\n",
    "Cs = [0.1, 1, 10, 20]\n",
    "gammas = ['scale', 'auto']\n",
    "errors = []\n",
    "\n",
    "#y1_train, y1_valid, y1_test, y1_train_valid = Y[:numTrain, 0], Y[numTrain:-numTest, 0], Y[-numTest:, 0], Y[:-numTest, 0]\n",
    "y2_train, y2_valid, y2_test, y2_train_valid = Y[:numTrain], Y[numTrain:-numTest], Y[-numTest:], Y[:-numTest]\n",
    "\"\"\"\n",
    "### SVR for y1\n",
    "for kern in kernels:\n",
    "    for ep in epsilons:\n",
    "        for C_ in Cs:\n",
    "            for gam in gammas:\n",
    "                svrModel = SVR(kernel=kern, gamma=gam, epsilon=ep, cache_size=2000, C=C_)\n",
    "                #                 svrModel.fit(X_train, y_train, sample_weight=train_weights)\n",
    "                svrModel.fit(X_train, y1_train)\n",
    "                y1_pred = svrModel.predict(X_valid)\n",
    "                error = metrics.mean_absolute_error(y1_valid, y1_pred)\n",
    "                errors.append(error)\n",
    "\n",
    "index_of_lowest_error = np.argmin(errors)\n",
    "\n",
    "best_kernel = kernels[int(index_of_lowest_error / (len(epsilons) * len(Cs) * len(gammas)))]  # Good\n",
    "best_ep = epsilons[\n",
    "    int((index_of_lowest_error % (len(epsilons) * len(Cs) * len(gammas))) / (len(Cs) * len(gammas)))]  # Good\n",
    "best_C = Cs[int((index_of_lowest_error % (len(Cs) * len(gammas))) / len(gammas))]  # Good\n",
    "best_gamma = gammas[index_of_lowest_error % len(gammas)]\n",
    "\n",
    "print(\"SVR Best kernel for y1 is: \", best_kernel)\n",
    "print(\"SVR Best Epsilon for y1 is: \", best_ep)\n",
    "print(\"SVR Best C for y1 is: \", best_C)\n",
    "print(\"SVR Best Gamma for y1 is: \", best_gamma)\n",
    "\n",
    "# # Make it run a little faster, hardcode best\n",
    "\n",
    "best_model = SVR(kernel=best_kernel, gamma=best_gamma, epsilon=best_ep, cache_size=2000, C=best_C)\n",
    "# best_model.fit(X_train_valid, y_train_valid, sample_weight=train_valid_weights)\n",
    "best_model.fit(X_train_valid, y1_train_valid)\n",
    "y1_pred = best_model.predict(X_test)\n",
    "\n",
    "predAndActual = pd.DataFrame({'Pred_y1': y1_pred, 'Test_y1': y1_test})\n",
    "predAndActual.to_csv(\"OverallSVRy1_buy_from_grid.csv\")\n",
    "\n",
    "print('SVR Mean Absolute Error for y1:', metrics.mean_absolute_error(y1_test, y1_pred))\n",
    "print('SVR Mean Squared Error for y1:', metrics.mean_squared_error(y1_test, y1_pred))\n",
    "print('SVR Root Mean Squared Error for y1:', np.sqrt(metrics.mean_squared_error(y1_test, y1_pred)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ending Support Vector Regression for y1 ------------------\")\n",
    "\"\"\"\n",
    "errors=[]\n",
    "### SVR for y2\n",
    "for kern in kernels:\n",
    "    for ep in epsilons:\n",
    "        for C_ in Cs:\n",
    "            for gam in gammas:\n",
    "                svrModel = SVR(kernel=kern, gamma=gam, epsilon=ep, cache_size=2000, C=C_)\n",
    "                #                 svrModel.fit(X_train, y_train, sample_weight=train_weights)\n",
    "                svrModel.fit(X_train, y2_train)\n",
    "                y2_pred = svrModel.predict(X_valid)\n",
    "                error = metrics.mean_absolute_error(y2_valid, y2_pred)\n",
    "                errors.append(error)\n",
    "\n",
    "index_of_lowest_error = np.argmin(errors)\n",
    "\n",
    "\n",
    "best_kernel = kernels[int(index_of_lowest_error / (len(epsilons) * len(Cs) * len(gammas)))]  # Good\n",
    "best_ep = epsilons[\n",
    "    int((index_of_lowest_error % (len(epsilons) * len(Cs) * len(gammas))) / (len(Cs) * len(gammas)))]  # Good\n",
    "best_C = Cs[int((index_of_lowest_error % (len(Cs) * len(gammas))) / len(gammas))]  # Good\n",
    "best_gamma = gammas[index_of_lowest_error % len(gammas)]\n",
    "\n",
    "print(\"SVR Best kernel for y2 is: \", best_kernel)\n",
    "print(\"SVR Best Epsilon for y2 is: \", best_ep)\n",
    "print(\"SVR Best C for y2 is: \", best_C)\n",
    "print(\"SVR Best Gamma for y2 is: \", best_gamma)\n",
    "\n",
    "# # Make it run a little faster, hardcode best\n",
    "\n",
    "best_model = SVR(kernel=best_kernel, gamma=best_gamma, epsilon=best_ep, cache_size=2000, C=best_C)\n",
    "# best_model.fit(X_train_valid, y_train_valid, sample_weight=train_valid_weights)\n",
    "best_model.fit(X_train_valid, y2_train_valid)\n",
    "y2_pred = best_model.predict(X_test)\n",
    "\n",
    "predAndActual = pd.DataFrame({'Pred_y2':y2_pred,'Test_y2':y2_test})\n",
    "predAndActual.to_csv(\"OverallSVRy2_FR_band.csv\")\n",
    "\n",
    "print('SVR Mean Absolute Error for y2:', metrics.mean_absolute_error(y2_test, y2_pred))\n",
    "print('SVR Mean Squared Error for y2:', metrics.mean_squared_error(y2_test, y2_pred))\n",
    "print('SVR Root Mean Squared Error for y2:', np.sqrt(metrics.mean_squared_error(y2_test, y2_pred)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Ending Support Vector Regression for y2------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Artificial Neural Network\n",
    "# Keras\n",
    "print(\"Starting Neural Network------------------\")\n",
    "X = x[0:500,:]\n",
    "Y = y[0:500,1]\n",
    "\n",
    "# Scaling X\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#Y = sc.fit_transform(Y)\n",
    "\n",
    "\n",
    "numData = 500\n",
    "numTrain = int(numData * 0.7)\n",
    "numTest = int(numData * .15)\n",
    "\n",
    "y_train, y_valid, y_test, y_train_valid = Y[:numTrain], Y[numTrain:-numTest], Y[-numTest:], Y[:-numTest]\n",
    "\n",
    "X_train, X_valid, X_test, X_train_valid = X[:numTrain, :], X[numTrain:-numTest, :], X[-numTest:, :], X[:-numTest, :]\n",
    "\n",
    "\n",
    "\n",
    "learningRates = [0.002, 0.005, 0.01, 0.02]\n",
    "batchSizes = [64, 128, 256]#, 512, 1024]\n",
    "dropoutRates = [0.00, 0.001, 0.01, 0.1]\n",
    "errors = []\n",
    "\n",
    "for lr_ in learningRates:\n",
    "    for bs in batchSizes:\n",
    "        for dr in dropoutRates:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(units=60, activation='sigmoid', input_dim=NumOfData+4))\n",
    "            model.add(Dropout(dr))\n",
    "            model.add(Dense(units=30, activation='sigmoid'))\n",
    "            #model.add(Dense(units=6, activation='sigmoid'))\n",
    "            #model.add(Dense(units=6, activation='sigmoid'))\n",
    "            model.add(Dense(units=1, activation='softplus'))\n",
    "\n",
    "            sgd = SGD(lr=lr_)\n",
    "            model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=bs, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "            y_pred = model.predict(X_valid, batch_size=bs)\n",
    "            #y_pred = y_pred.flatten()\n",
    "\n",
    "            error = metrics.mean_absolute_error(y_valid, y_pred)\n",
    "            errors.append(error)\n",
    "\n",
    "index_of_lowest_error = np.argmin(errors)\n",
    "\n",
    "\n",
    "best_lr = learningRates[int(index_of_lowest_error / (len(batchSizes) * len(dropoutRates)))]  # Good\n",
    "best_bs = batchSizes[int((index_of_lowest_error % (len(batchSizes) * len(dropoutRates))) / len(dropoutRates))]  # Good\n",
    "best_dr = dropoutRates[index_of_lowest_error % len(dropoutRates)]  # Good\n",
    "print(\"ANN Best Learning Rate is: \", best_lr)\n",
    "print(\"ANN Best Batch Size is: \", best_bs)\n",
    "print(\"ANN Best Dropout Rate is: \", best_dr)\n",
    "\n",
    "# Using best values\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='sigmoid', input_dim=NumOfData+4))\n",
    "model.add(Dropout(best_dr))\n",
    "model.add(Dense(units=30, activation='sigmoid'))\n",
    "#model.add(Dense(units=6, activation='sigmoid'))\n",
    "#model.add(Dense(units=6, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='softplus'))\n",
    "\n",
    "sgd = SGD(lr=best_lr)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_valid, y_train_valid, epochs=1000, batch_size=best_bs, verbose=0)\n",
    "\n",
    "# loss_and_metrics = model.evaluate(X_test, y_test,batch_size=best_bs)\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=best_bs)\n",
    "predAndActual = pd.DataFrame({'Pred_y2':y2_pred,'Test_y2':y2_test})\n",
    "#pd.DataFrame({'Pred_y1': y_pred[:,0], 'Test_y1': y_test[:,0],'Pred_y2':y_pred[:,1],'Test_y2':y_test[:,1]})\n",
    "predAndActual.to_csv(\"ArtifitialMachineLearning.csv\")\n",
    "#y_pred = y_pred.flatten()\n",
    "\n",
    "print('ANN Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('ANN Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('ANN Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print(\"Ending Neural Network Regression ------------------\")\n",
    "\n",
    "#end = time.time()\n",
    "#duration = end - start\n",
    "#print(\"Execution Time is:\", duration /60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
